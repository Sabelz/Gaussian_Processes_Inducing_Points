{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# Gaussian Process on the concrete UCI dataset, using Inducing Points and all points"],"metadata":{"id":"B85Qx-BF5HO_"}},{"cell_type":"markdown","source":["# Github"],"metadata":{"id":"5paJvVyl5OLq"}},{"cell_type":"code","source":["from google.colab import drive # For github\n","drive.mount('/content/drive')\n","%cd /content/drive/MyDrive/Project18/GPs\n","!git config --global user.email \"alexander.sabelstrom.1040@student.uu.se\"\n","!git config --global user.name \"Sabelz\""],"metadata":{"id":"V5A5PN5l5PPZ","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1700414132970,"user_tz":-60,"elapsed":19002,"user":{"displayName":"Alexander Sabelström","userId":"16302195271000866589"}},"outputId":"8ce6f4a5-6f75-4c00-955e-de3e56202fbb"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n","/content/drive/MyDrive/Project18/GPs\n"]}]},{"cell_type":"markdown","source":["# Imports"],"metadata":{"id":"rn7ILTSA5Rfq"}},{"cell_type":"code","source":["import numpy as np\n","import matplotlib.pyplot as plt\n","import torch\n","!pip install gpytorch\n","import gpytorch\n","\n","%matplotlib inline\n","%load_ext autoreload\n","%autoreload 2\n","%run ../datasets/concrete.ipynb # Run the toy notebook which is in the datasets folder(toy dataset)\n"],"metadata":{"id":"vz2DJ5ZU5ShE","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1700414597043,"user_tz":-60,"elapsed":12031,"user":{"displayName":"Alexander Sabelström","userId":"16302195271000866589"}},"outputId":"0791b41f-7e27-4b4b-c74b-533ab4b8fd9b"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: gpytorch in /usr/local/lib/python3.10/dist-packages (1.11)\n","Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from gpytorch) (1.2.2)\n","Requirement already satisfied: linear-operator>=0.5.0 in /usr/local/lib/python3.10/dist-packages (from gpytorch) (0.5.2)\n","Requirement already satisfied: torch>=1.11 in /usr/local/lib/python3.10/dist-packages (from linear-operator>=0.5.0->gpytorch) (2.1.0+cu118)\n","Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from linear-operator>=0.5.0->gpytorch) (1.11.3)\n","Requirement already satisfied: jaxtyping>=0.2.9 in /usr/local/lib/python3.10/dist-packages (from linear-operator>=0.5.0->gpytorch) (0.2.23)\n","Requirement already satisfied: typeguard~=2.13.3 in /usr/local/lib/python3.10/dist-packages (from linear-operator>=0.5.0->gpytorch) (2.13.3)\n","Requirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->gpytorch) (1.23.5)\n","Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->gpytorch) (1.3.2)\n","Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->gpytorch) (3.2.0)\n","Requirement already satisfied: typing-extensions>=3.7.4.1 in /usr/local/lib/python3.10/dist-packages (from jaxtyping>=0.2.9->linear-operator>=0.5.0->gpytorch) (4.5.0)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.11->linear-operator>=0.5.0->gpytorch) (3.13.1)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.11->linear-operator>=0.5.0->gpytorch) (1.12)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.11->linear-operator>=0.5.0->gpytorch) (3.2.1)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11->linear-operator>=0.5.0->gpytorch) (3.1.2)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.11->linear-operator>=0.5.0->gpytorch) (2023.6.0)\n","Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11->linear-operator>=0.5.0->gpytorch) (2.1.0)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.11->linear-operator>=0.5.0->gpytorch) (2.1.3)\n","Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.11->linear-operator>=0.5.0->gpytorch) (1.3.0)\n","The autoreload extension is already loaded. To reload it, use:\n","  %reload_ext autoreload\n","Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n","/content/drive/MyDrive/Project18/datasets\n","<class 'pandas.core.frame.DataFrame'>\n","RangeIndex: 1030 entries, 0 to 1029\n","Data columns (total 9 columns):\n"," #   Column                                                 Non-Null Count  Dtype  \n","---  ------                                                 --------------  -----  \n"," 0   Cement (component 1)(kg in a m^3 mixture)              1030 non-null   float64\n"," 1   Blast Furnace Slag (component 2)(kg in a m^3 mixture)  1030 non-null   float64\n"," 2   Fly Ash (component 3)(kg in a m^3 mixture)             1030 non-null   float64\n"," 3   Water  (component 4)(kg in a m^3 mixture)              1030 non-null   float64\n"," 4   Superplasticizer (component 5)(kg in a m^3 mixture)    1030 non-null   float64\n"," 5   Coarse Aggregate  (component 6)(kg in a m^3 mixture)   1030 non-null   float64\n"," 6   Fine Aggregate (component 7)(kg in a m^3 mixture)      1030 non-null   float64\n"," 7   Age (day)                                              1030 non-null   int64  \n"," 8   Concrete compressive strength(MPa, megapascals)        1030 non-null   float64\n","dtypes: float64(8), int64(1)\n","memory usage: 72.5 KB\n","None\n","\n","Cement (component 1)(kg in a m^3 mixture)                False\n","Blast Furnace Slag (component 2)(kg in a m^3 mixture)    False\n","Fly Ash (component 3)(kg in a m^3 mixture)               False\n","Water  (component 4)(kg in a m^3 mixture)                False\n","Superplasticizer (component 5)(kg in a m^3 mixture)      False\n","Coarse Aggregate  (component 6)(kg in a m^3 mixture)     False\n","Fine Aggregate (component 7)(kg in a m^3 mixture)        False\n","Age (day)                                                False\n","Concrete compressive strength(MPa, megapascals)          False\n","dtype: bool\n"]}]},{"cell_type":"markdown","source":["# Training/Test data from concrete.ipynb"],"metadata":{"id":"zp_VG3eh5hB-"}},{"cell_type":"code","source":["concrete_data = df_Concrete # df_Concrete is defined in ../datasets/concrete.ipynb\n","x, y = concrete_data.iloc[:, :-1].to_numpy() , concrete_data.iloc[:, -1].to_numpy()  # The last column is output(concrete compressive strength)\n","# Normalize\n","x_mean = x.mean(axis = 0) # mean for each feature\n","x_std = x.std(axis = 0) # std for each feature\n","y_mean = y.mean() # mean for output\n","y_std = y.std() # std for output\n","x = (x-x_mean) / x_std\n","y = (y-y_mean) / y_std\n","# Convert them to tensors\n","x = torch.from_numpy(x).float()\n","y = torch.from_numpy(y).float()\n","\n","# Split into training and test data\n","len_split = int(0.8 * len(x)) # Where the training points should be split\n","# The first 80% of points\n","xTrain = x[:len_split]\n","yTrain = y[:len_split]\n","# The last 20% of points\n","xTest = x[len_split:]\n","yTest = y[len_split:]\n","\n","print(xTrain.size(), yTrain.size(), xTest.size(), yTest.size())"],"metadata":{"id":"5-bzpgR55hds","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1700423368777,"user_tz":-60,"elapsed":382,"user":{"displayName":"Alexander Sabelström","userId":"16302195271000866589"}},"outputId":"8acd614d-aea0-4291-d028-82be71721f44"},"execution_count":101,"outputs":[{"output_type":"stream","name":"stdout","text":["torch.Size([824, 8]) torch.Size([824]) torch.Size([206, 8]) torch.Size([206])\n"]}]},{"cell_type":"markdown","source":["# Inducing Points"],"metadata":{"id":"k5fupiIE6RSP"}},{"cell_type":"code","source":["amount_of_points = 30\n","inducingPointsX = xTrain[:amount_of_points] # Choose how many points to pick\n","inducingPointsY = yTrain[:amount_of_points] # Choose how many points to pick\n","print(len(inducingPointsX))"],"metadata":{"id":"-EfKtYr06Tri","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1700423394029,"user_tz":-60,"elapsed":233,"user":{"displayName":"Alexander Sabelström","userId":"16302195271000866589"}},"outputId":"f96a8375-54c9-4d32-ba7b-d1996ae12b87"},"execution_count":102,"outputs":[{"output_type":"stream","name":"stdout","text":["30\n"]}]},{"cell_type":"markdown","source":["# The GP model"],"metadata":{"id":"7I237Uom5qh1"}},{"cell_type":"code","source":["# Class for the GP model(Exact GP)\n","class GPModel(gpytorch.models.ExactGP):\n","    def __init__(self, x_Inducing, y_Inducing, likelihood):\n","        super(GPModel, self).__init__(x_Inducing, y_Inducing, likelihood)\n","        self.mean_module = gpytorch.means.ConstantMean() # Decide which mean to use\n","        self.covar_module = gpytorch.kernels.ScaleKernel(gpytorch.kernels.RBFKernel()) # Decide which kernel to use\n","    # GP Posterior predictive distribution\n","    def forward(self, x):\n","        mean_x = self.mean_module(x)\n","        covar_x = self.covar_module(x)\n","        return gpytorch.distributions.MultivariateNormal(mean_x, covar_x)"],"metadata":{"id":"y9Z-d3uJ5u0J","executionInfo":{"status":"ok","timestamp":1700423396778,"user_tz":-60,"elapsed":4,"user":{"displayName":"Alexander Sabelström","userId":"16302195271000866589"}}},"execution_count":103,"outputs":[]},{"cell_type":"markdown","source":["# Initialize the first model"],"metadata":{"id":"yxSyoOSg5zCb"}},{"cell_type":"code","source":["# initialize likelihood and model\n","likelihood = gpytorch.likelihoods.GaussianLikelihood() # Decide likelihood\n","model = GPModel(inducingPointsX, inducingPointsY, likelihood) # Send in inducing points as the training points\n","if torch.cuda.is_available():\n","    model = model.cuda()\n","    likelihood = likelihood.cuda()"],"metadata":{"id":"iOHyr2ao5ziS","executionInfo":{"status":"ok","timestamp":1700423398226,"user_tz":-60,"elapsed":238,"user":{"displayName":"Alexander Sabelström","userId":"16302195271000866589"}}},"execution_count":104,"outputs":[]},{"cell_type":"markdown","source":["# Training Function"],"metadata":{"id":"d6-SpNNl52Zp"}},{"cell_type":"code","source":["import os\n","def train(model, xTrain, yTrain): # Train the model on training data: xTrain, yTrain\n","\n","  smoke_test = ('CI' in os.environ)\n","  training_iter = 2 if smoke_test else 250\n","\n","\n","  # Find optimal model hyperparameters\n","  model.train()\n","  model.likelihood.train()\n","\n","  # Use the adam optimizer\n","  optimizer = torch.optim.Adam(model.parameters(), lr=0.1)  # Includes GaussianLikelihood parameters\n","\n","  # \"Loss\" for GPs - the marginal log likelihood\n","  mll = gpytorch.mlls.ExactMarginalLogLikelihood(model.likelihood, model)\n","  # Train without printing to ensure the training method is as fast as possible\n","  for i in range(training_iter):\n","      # Zero gradients from previous iteration\n","      optimizer.zero_grad()\n","      # Output from model\n","      output = model(xTrain)\n","      # Calc loss and backprop gradients\n","      loss = -mll(output, yTrain)\n","      loss.backward()\n","      optimizer.step()\n"],"metadata":{"id":"GQYCTyGQ511G","executionInfo":{"status":"ok","timestamp":1700423399774,"user_tz":-60,"elapsed":2,"user":{"displayName":"Alexander Sabelström","userId":"16302195271000866589"}}},"execution_count":105,"outputs":[]},{"cell_type":"markdown","source":["# Train the Model#"],"metadata":{"id":"qIcdsvoRWIuH"}},{"cell_type":"code","source":["%time train(model, inducingPointsX, inducingPointsY)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"24WA9ODFWKc_","executionInfo":{"status":"ok","timestamp":1700423402866,"user_tz":-60,"elapsed":1008,"user":{"displayName":"Alexander Sabelström","userId":"16302195271000866589"}},"outputId":"b36d0a3b-3110-47b9-ffbd-4fe31a8c4f95"},"execution_count":106,"outputs":[{"output_type":"stream","name":"stdout","text":["CPU times: user 804 ms, sys: 11.5 ms, total: 815 ms\n","Wall time: 822 ms\n"]}]},{"cell_type":"markdown","source":["# The posterior mean, variance and Covariance Matrix"],"metadata":{"id":"dZvPkg1Y5-eb"}},{"cell_type":"code","source":["model.eval() # eval mode is for computing predictions through the model posterior\n","f_preds = model(xTest) # returns the model posterior distribution p(f* | x*, X, y), for training data X, y\n","f_mean = f_preds.mean # Predictive mean\n","f_var = f_preds.variance # Predictive variance\n","f_covar = f_preds.covariance_matrix # Covariance matrix\n","print(\"Mean Dimension: \", f_mean.size())\n","print()\n","print(\"Variance Dimension: \", f_var.size())\n","print()\n","print(\"CovMatrix Dimension \", f_covar.size())"],"metadata":{"id":"KDt3gBNy6AnX","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1700423405633,"user_tz":-60,"elapsed":367,"user":{"displayName":"Alexander Sabelström","userId":"16302195271000866589"}},"outputId":"01394ff1-5399-4cea-aaa9-fea1384f2006"},"execution_count":107,"outputs":[{"output_type":"stream","name":"stdout","text":["Mean Dimension:  torch.Size([206])\n","\n","Variance Dimension:  torch.Size([206])\n","\n","CovMatrix Dimension  torch.Size([206, 206])\n"]}]},{"cell_type":"markdown","source":["# Predictive Distribution"],"metadata":{"id":"wm_kDQbW6H0G"}},{"cell_type":"code","source":["model.eval() # eval mode is for computing predictions through the model posterior.\n","likelihood.eval()\n","\n","# Make predictions by feeding model through likelihood\n","with torch.no_grad(), gpytorch.settings.fast_pred_var(): # https://arxiv.org/abs/1803.06058\n","    observed_pred = likelihood(model(xTest))# gives us the posterior predictive distribution p(y* | x*, X, y) which is the probability distribution over the predicted output value\n","    mean = observed_pred.mean.numpy()"],"metadata":{"id":"YEUJIZsJ6I1i","executionInfo":{"status":"ok","timestamp":1700423411293,"user_tz":-60,"elapsed":233,"user":{"displayName":"Alexander Sabelström","userId":"16302195271000866589"}}},"execution_count":108,"outputs":[]},{"cell_type":"markdown","source":["# Compare different amount of points"],"metadata":{"id":"1r6MvhHyJdRM"}},{"cell_type":"code","source":["# Trains models one by one for each amount of inducing points, and plots each model with plots [rows,columns](must match the length of listOfPoints)\n","def severalInducingPoints(listOfPoints):\n","  maxPoints = len(xTrain) # The max amount of points in training points\n","  for points in listOfPoints:\n","    inducingPointsX = xTrain[:points] # Choose how many points to pick\n","    inducingPointsY = yTrain[:points] # Choose how many points to pick\n","\n","    # initialize likelihood and model\n","    likelihood = gpytorch.likelihoods.GaussianLikelihood() # Decide likelihood\n","    model = GPModel(inducingPointsX, inducingPointsY, likelihood) # Send in inducing points as the training points\n","    if torch.cuda.is_available():\n","        model = model.cuda()\n","        likelihood = likelihood.cuda()\n","    print()\n","    print(\"Inducing Points: \", points)\n","\n","    %timeit train(model, inducingPointsX, inducingPointsY) # Train the model\n","    # Plot\n","    model.eval() # eval mode is for computing predictions through the model posterior.\n","    likelihood.eval()\n","\n","severalInducingPoints([5,10,50,100,200,400, 700, 900, 1030]) # With 1030 being all points\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"dJeE8SmtJibw","executionInfo":{"status":"ok","timestamp":1700424049470,"user_tz":-60,"elapsed":504597,"user":{"displayName":"Alexander Sabelström","userId":"16302195271000866589"}},"outputId":"4236d709-7b17-4c45-9c46-1702bb003d92"},"execution_count":111,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","Inducing Points:  5\n","757 ms ± 111 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n","\n","Inducing Points:  10\n","947 ms ± 125 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n","\n","Inducing Points:  50\n","802 ms ± 17.7 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n","\n","Inducing Points:  100\n","1.23 s ± 138 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n","\n","Inducing Points:  200\n","1.41 s ± 217 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n","\n","Inducing Points:  400\n","3.86 s ± 550 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n","\n","Inducing Points:  700\n","13.6 s ± 640 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n","\n","Inducing Points:  900\n","20.8 s ± 678 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n","\n","Inducing Points:  1030\n","20.9 s ± 762 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"]}]}]}