{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Gaussian Process on the Toy dataset, using Inducing Points"
      ],
      "metadata": {
        "id": "B85Qx-BF5HO_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Github"
      ],
      "metadata": {
        "id": "5paJvVyl5OLq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive # For github\n",
        "drive.mount('/content/drive')\n",
        "%cd /content/drive/MyDrive/Project18/GPs\n",
        "!git config --global user.email \"alexander.sabelstrom.1040@student.uu.se\"\n",
        "!git config --global user.name \"Sabelz\""
      ],
      "metadata": {
        "id": "V5A5PN5l5PPZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Imports"
      ],
      "metadata": {
        "id": "rn7ILTSA5Rfq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "#!pip install gpytorch\n",
        "import gpytorch\n",
        "\n",
        "%matplotlib inline\n",
        "%load_ext autoreload\n",
        "%autoreload 2\n",
        "%run ../datasets/toy.ipynb # Run the toy notebook which is in the datasets folder(toy dataset)\n"
      ],
      "metadata": {
        "id": "vz2DJ5ZU5ShE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training data from toy.ipynb"
      ],
      "metadata": {
        "id": "zp_VG3eh5hB-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "xTrain, yTrain = x, y # x, y are defined in ../datasets/toy.ipynb\n",
        "xTrain, yTrain = torch.from_numpy(xTrain), torch.from_numpy(yTrain) # Convert them to tensors"
      ],
      "metadata": {
        "id": "5-bzpgR55hds"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Inducing Points"
      ],
      "metadata": {
        "id": "k5fupiIE6RSP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Start here?"
      ],
      "metadata": {
        "id": "-EfKtYr06Tri"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# The GP model"
      ],
      "metadata": {
        "id": "7I237Uom5qh1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Class for the GP model(Exact GP)\n",
        "class GPModel(gpytorch.models.ExactGP):\n",
        "    def __init__(self, train_x, train_y, likelihood):\n",
        "        super(GPModel, self).__init__(train_x, train_y, likelihood)\n",
        "        self.mean_module = gpytorch.means.ConstantMean() # Decide which mean to use\n",
        "        self.covar_module = gpytorch.kernels.ScaleKernel(gpytorch.kernels.RBFKernel()) # Decide which kernel to use\n",
        "    # GP Posterior predictive distribution\n",
        "    def forward(self, x):\n",
        "        mean_x = self.mean_module(x)\n",
        "        covar_x = self.covar_module(x)\n",
        "        return gpytorch.distributions.MultivariateNormal(mean_x, covar_x)"
      ],
      "metadata": {
        "id": "y9Z-d3uJ5u0J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Initialize the first model"
      ],
      "metadata": {
        "id": "yxSyoOSg5zCb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# initialize likelihood and model\n",
        "likelihood = gpytorch.likelihoods.GaussianLikelihood() # Decide likelihood\n",
        "model = GPModel(xTrain, yTrain, likelihood) # For the first example, RBF kernel is used"
      ],
      "metadata": {
        "id": "iOHyr2ao5ziS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Train the model"
      ],
      "metadata": {
        "id": "d6-SpNNl52Zp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "smoke_test = ('CI' in os.environ)\n",
        "training_iter = 2 if smoke_test else 50\n",
        "\n",
        "\n",
        "# Find optimal model hyperparameters\n",
        "model.train()\n",
        "likelihood.train()\n",
        "\n",
        "# Use the adam optimizer\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.1)  # Includes GaussianLikelihood parameters\n",
        "\n",
        "# \"Loss\" for GPs - the marginal log likelihood\n",
        "mll = gpytorch.mlls.ExactMarginalLogLikelihood(likelihood, model)\n",
        "\n",
        "for i in range(training_iter):\n",
        "    # Zero gradients from previous iteration\n",
        "    optimizer.zero_grad()\n",
        "    # Output from model\n",
        "    output = model(xTrain)\n",
        "    # Calc loss and backprop gradients\n",
        "    loss = -mll(output, yTrain)\n",
        "    loss.backward()\n",
        "    print('Iter %d/%d - Loss: %.3f   lengthscale: %.3f   noise: %.3f' % (\n",
        "        i + 1, training_iter, loss.item(),\n",
        "        model.covar_module.base_kernel.lengthscale.item(),\n",
        "        model.likelihood.noise.item()\n",
        "    ))\n",
        "    optimizer.step()"
      ],
      "metadata": {
        "id": "GQYCTyGQ511G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Test data"
      ],
      "metadata": {
        "id": "GVYsUnvQ56Bi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Observing the plot of the toy dataset, x varies between -7-7\n",
        "xTest = torch.linspace(-9, 9, 50)"
      ],
      "metadata": {
        "id": "nRoTQ0Vd570K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# The posterior mean, variance and Covariance Matrix"
      ],
      "metadata": {
        "id": "dZvPkg1Y5-eb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.eval() # eval mode is for computing predictions through the model posterior\n",
        "f_preds = model(xTest) # returns the model posterior distribution p(f* | x*, X, y), for training data X, y\n",
        "f_mean = f_preds.mean # Predictive mean\n",
        "f_var = f_preds.variance # Predictive variance\n",
        "f_covar = f_preds.covariance_matrix # Covariance matrix\n",
        "print(\"Mean Dimension: \", f_mean.size())\n",
        "print()\n",
        "print(\"Variance Dimension: \", f_var.size())\n",
        "print()\n",
        "print(\"CovMatrix Dimension \", f_covar.size())"
      ],
      "metadata": {
        "id": "KDt3gBNy6AnX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Plots of samples from the GP"
      ],
      "metadata": {
        "id": "W_Of6w6V6CLd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert to numpy\n",
        "xTestPlot = xTest.detach().numpy()\n",
        "f_meanPlot = f_mean.detach().numpy()\n",
        "f_varPlot = f_var.detach().numpy()\n",
        "# Plot samples from the GP\n",
        "plt.figure(figsize=(10, 4))\n",
        "for i in range(20):  # Generate 20 samples\n",
        "    f_sample = f_preds.sample().detach().numpy()\n",
        "    plt.plot(xTestPlot, f_sample)\n",
        "plt.title('Samples from the GP')\n",
        "plt.show()\n",
        "# Plot variance\n",
        "plt.figure(figsize=(10, 5))\n",
        "plt.plot(xTestPlot, f_varPlot, 'purple')\n",
        "plt.title('Variance across Test Points')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "8PnUCq0k6GYj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Predictive Distribution"
      ],
      "metadata": {
        "id": "wm_kDQbW6H0G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.eval() # eval mode is for computing predictions through the model posterior.\n",
        "likelihood.eval()\n",
        "\n",
        "\n",
        "\n",
        "# Make predictions by feeding model through likelihood\n",
        "with torch.no_grad(), gpytorch.settings.fast_pred_var(): # https://arxiv.org/abs/1803.06058\n",
        "    observed_pred = likelihood(model(xTest))# gives us the posterior predictive distribution p(y* | x*, X, y) which is the probability distribution over the predicted output value"
      ],
      "metadata": {
        "id": "YEUJIZsJ6I1i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Plot with RBF kernel"
      ],
      "metadata": {
        "id": "SsoNAT006MH2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "with torch.no_grad():\n",
        "    # Initialize plot\n",
        "    f, ax = plt.subplots(1, 1, figsize=(4, 3))\n",
        "\n",
        "    # Get upper and lower confidence bounds\n",
        "    lower, upper = observed_pred.confidence_region()\n",
        "    # Plot training data as black stars\n",
        "    ax.plot(xTrain.numpy(), yTrain.numpy(), 'k.')\n",
        "    # Plot predictive means as purple line\n",
        "    ax.plot(xTest.numpy(), observed_pred.mean.numpy(), 'purple')\n",
        "    # Shade between the lower and upper confidence bounds\n",
        "    ax.fill_between(xTest.numpy(), lower.numpy(), upper.numpy(), alpha=0.5)\n",
        "    ax.set_ylim([-1, 2])\n",
        "    ax.legend(['Observed Data', 'Mean', 'Confidence'])"
      ],
      "metadata": {
        "id": "e52APwfA6OUN"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}