{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# Gaussian Process on the concrete UCI dataset, using Inducing Points and all points"],"metadata":{"id":"B85Qx-BF5HO_"}},{"cell_type":"markdown","source":["# Github"],"metadata":{"id":"5paJvVyl5OLq"}},{"cell_type":"code","source":["from google.colab import drive # For github\n","drive.mount('/content/drive')\n","%cd /content/drive/MyDrive/Project18/GPs\n","!git config --global user.email \"alexander.sabelstrom.1040@student.uu.se\"\n","!git config --global user.name \"Sabelz\""],"metadata":{"id":"V5A5PN5l5PPZ","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1700580156782,"user_tz":-60,"elapsed":21721,"user":{"displayName":"Alexander Sabelström","userId":"16302195271000866589"}},"outputId":"fd226d9a-3462-45a0-e16c-52fbae6f92df"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n","/content/drive/MyDrive/Project18/GPs\n"]}]},{"cell_type":"markdown","source":["# Imports"],"metadata":{"id":"rn7ILTSA5Rfq"}},{"cell_type":"code","source":["import numpy as np\n","import matplotlib.pyplot as plt\n","import torch\n","#!pip install gpytorch\n","import gpytorch\n","from sklearn.model_selection import train_test_split\n","import math\n","%matplotlib inline\n","%load_ext autoreload\n","%autoreload 2\n","%run ../datasets/concrete.ipynb # Run the toy notebook which is in the datasets folder(toy dataset)\n"],"metadata":{"id":"vz2DJ5ZU5ShE","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1700582313168,"user_tz":-60,"elapsed":2115,"user":{"displayName":"Alexander Sabelström","userId":"16302195271000866589"}},"outputId":"48edbd80-b45a-4edb-eed7-31ec49a3d137"},"execution_count":24,"outputs":[{"output_type":"stream","name":"stdout","text":["The autoreload extension is already loaded. To reload it, use:\n","  %reload_ext autoreload\n","Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n","/content/drive/MyDrive/Project18/datasets\n","<class 'pandas.core.frame.DataFrame'>\n","RangeIndex: 1030 entries, 0 to 1029\n","Data columns (total 9 columns):\n"," #   Column                                                 Non-Null Count  Dtype  \n","---  ------                                                 --------------  -----  \n"," 0   Cement (component 1)(kg in a m^3 mixture)              1030 non-null   float64\n"," 1   Blast Furnace Slag (component 2)(kg in a m^3 mixture)  1030 non-null   float64\n"," 2   Fly Ash (component 3)(kg in a m^3 mixture)             1030 non-null   float64\n"," 3   Water  (component 4)(kg in a m^3 mixture)              1030 non-null   float64\n"," 4   Superplasticizer (component 5)(kg in a m^3 mixture)    1030 non-null   float64\n"," 5   Coarse Aggregate  (component 6)(kg in a m^3 mixture)   1030 non-null   float64\n"," 6   Fine Aggregate (component 7)(kg in a m^3 mixture)      1030 non-null   float64\n"," 7   Age (day)                                              1030 non-null   int64  \n"," 8   Concrete compressive strength(MPa, megapascals)        1030 non-null   float64\n","dtypes: float64(8), int64(1)\n","memory usage: 72.5 KB\n","None\n","\n","Cement (component 1)(kg in a m^3 mixture)                False\n","Blast Furnace Slag (component 2)(kg in a m^3 mixture)    False\n","Fly Ash (component 3)(kg in a m^3 mixture)               False\n","Water  (component 4)(kg in a m^3 mixture)                False\n","Superplasticizer (component 5)(kg in a m^3 mixture)      False\n","Coarse Aggregate  (component 6)(kg in a m^3 mixture)     False\n","Fine Aggregate (component 7)(kg in a m^3 mixture)        False\n","Age (day)                                                False\n","Concrete compressive strength(MPa, megapascals)          False\n","dtype: bool\n"]}]},{"cell_type":"markdown","source":["# Training/Test data from concrete.ipynb"],"metadata":{"id":"zp_VG3eh5hB-"}},{"cell_type":"code","source":["# Set a seed for reproducibility\n","np.random.seed(52)\n","\n","concrete_data = df_Concrete # df_Concrete is defined in ../datasets/concrete.ipynb\n","x, y = concrete_data.iloc[:, :-1].to_numpy() , concrete_data.iloc[:, -1].to_numpy()  # The last column is output(concrete compressive strength)\n","\n","# Split into training and validation datasets\n","xTrain, xTest, yTrain, yTest = train_test_split(x, y, test_size=0.1)\n","# Normalize training points\n","xTrain_mean = xTrain.mean(axis = 0) # mean for each feature\n","xTrain_std = xTrain.std(axis = 0) # std for each feature\n","yTrain_mean = yTrain.mean() # mean for output\n","yTrain_std = yTrain.std() # std for output\n","xTrain = (xTrain-xTrain_mean) / xTrain_std\n","yTrain = (yTrain-yTrain_mean) / yTrain_std\n","\n","# Normalize test points\n","xTest_mean = xTest.mean(axis = 0) # mean for each feature\n","xTest_std = xTest.std(axis = 0) # std for each feature\n","yTest_mean = yTest.mean() # mean for output\n","yTest_std = yTest.std() # std for output\n","xTest = (xTest-xTest_mean) / xTest_std\n","yTest = (yTest-yTest_mean) / yTest_std\n","\n","# Convert them to tensors\n","xTrain = torch.from_numpy(xTrain).float()\n","yTrain = torch.from_numpy(yTrain).float()\n","\n","xTest = torch.from_numpy(xTest).float()\n","yTest = torch.from_numpy(yTest).float()\n","\n","print(xTrain.size(), yTrain.size(), xTest.size(), yTest.size())"],"metadata":{"id":"5-bzpgR55hds","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1700582468134,"user_tz":-60,"elapsed":4,"user":{"displayName":"Alexander Sabelström","userId":"16302195271000866589"}},"outputId":"14be2a18-70b4-469f-b3a0-4fbd19aee0ab"},"execution_count":30,"outputs":[{"output_type":"stream","name":"stdout","text":["torch.Size([927, 8]) torch.Size([927]) torch.Size([103, 8]) torch.Size([103])\n"]}]},{"cell_type":"markdown","source":["# The GP model"],"metadata":{"id":"7I237Uom5qh1"}},{"cell_type":"code","source":["# Class for the GP model(Exact GP)\n","class GPModel(gpytorch.models.ExactGP):\n","    def __init__(self, x, y, likelihood):\n","        super(GPModel, self).__init__(x, y, likelihood)\n","        self.mean_module = gpytorch.means.ConstantMean() # Decide which mean to use\n","        self.covar_module = gpytorch.kernels.ScaleKernel(gpytorch.kernels.RBFKernel()) # Decide which kernel to use\n","    # GP Posterior predictive distribution\n","    def forward(self, x):\n","        mean_x = self.mean_module(x)\n","        covar_x = self.covar_module(x)\n","        return gpytorch.distributions.MultivariateNormal(mean_x, covar_x)"],"metadata":{"id":"y9Z-d3uJ5u0J","executionInfo":{"status":"ok","timestamp":1700581570455,"user_tz":-60,"elapsed":258,"user":{"displayName":"Alexander Sabelström","userId":"16302195271000866589"}}},"execution_count":13,"outputs":[]},{"cell_type":"markdown","source":["# Initialize the first model"],"metadata":{"id":"yxSyoOSg5zCb"}},{"cell_type":"code","source":["# initialize likelihood and model\n","likelihood = gpytorch.likelihoods.GaussianLikelihood() # Decide likelihood\n","model = GPModel(xTrain, yTrain, likelihood) # Use training points and given likelihood\n","if torch.cuda.is_available():\n","    model = model.cuda()\n","    likelihood = likelihood.cuda()"],"metadata":{"id":"iOHyr2ao5ziS","executionInfo":{"status":"ok","timestamp":1700582471724,"user_tz":-60,"elapsed":374,"user":{"displayName":"Alexander Sabelström","userId":"16302195271000866589"}}},"execution_count":31,"outputs":[]},{"cell_type":"markdown","source":["# Training Function"],"metadata":{"id":"d6-SpNNl52Zp"}},{"cell_type":"code","source":["import os\n","def train(model, xTrain, yTrain): # Train the model on training data: xTrain, yTrain\n","\n","  smoke_test = ('CI' in os.environ)\n","  training_iter = 2 if smoke_test else 250\n","\n","\n","  # Find optimal model hyperparameters\n","  model.train()\n","  model.likelihood.train()\n","\n","  # Use the adam optimizer\n","  optimizer = torch.optim.Adam(model.parameters(), lr=0.1)  # Includes GaussianLikelihood parameters\n","\n","  # \"Loss\" for GPs - the marginal log likelihood\n","  mll = gpytorch.mlls.ExactMarginalLogLikelihood(model.likelihood, model)\n","  # Train without printing to ensure the training method is as fast as possible\n","  for i in range(training_iter):\n","      # Zero gradients from previous iteration\n","      optimizer.zero_grad()\n","      # Output from model\n","      output = model(xTrain)\n","      # Calc loss and backprop gradients\n","      loss = -mll(output, yTrain)\n","      loss.backward()\n","      optimizer.step()\n"],"metadata":{"id":"GQYCTyGQ511G","executionInfo":{"status":"ok","timestamp":1700582475231,"user_tz":-60,"elapsed":368,"user":{"displayName":"Alexander Sabelström","userId":"16302195271000866589"}}},"execution_count":32,"outputs":[]},{"cell_type":"markdown","source":["# Train the Model#"],"metadata":{"id":"qIcdsvoRWIuH"}},{"cell_type":"code","source":["%time train(model, xTrain, yTrain)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"24WA9ODFWKc_","executionInfo":{"status":"ok","timestamp":1700582496667,"user_tz":-60,"elapsed":19404,"user":{"displayName":"Alexander Sabelström","userId":"16302195271000866589"}},"outputId":"996134b9-5bf9-4ef0-e7fd-b6c819d12c0a"},"execution_count":33,"outputs":[{"output_type":"stream","name":"stdout","text":["CPU times: user 18 s, sys: 892 ms, total: 18.9 s\n","Wall time: 19.1 s\n"]}]},{"cell_type":"markdown","source":["# The posterior mean, variance and Covariance Matrix"],"metadata":{"id":"dZvPkg1Y5-eb"}},{"cell_type":"code","source":["model.eval() # eval mode is for computing predictions through the model posterior\n","f_preds = model(xTest) # returns the model posterior distribution p(f* | x*, X, y), for training data X, y\n","f_mean = f_preds.mean # Predictive mean\n","f_var = f_preds.variance # Predictive variance\n","f_covar = f_preds.covariance_matrix # Covariance matrix\n","print(\"Mean Dimension: \", f_mean.size())\n","print()\n","print(\"Variance Dimension: \", f_var.size())\n","print()\n","print(\"CovMatrix Dimension \", f_covar.size())"],"metadata":{"id":"KDt3gBNy6AnX","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1700582559361,"user_tz":-60,"elapsed":617,"user":{"displayName":"Alexander Sabelström","userId":"16302195271000866589"}},"outputId":"b8644272-9b70-411a-830a-c620fbd30f5c"},"execution_count":34,"outputs":[{"output_type":"stream","name":"stdout","text":["Mean Dimension:  torch.Size([103])\n","\n","Variance Dimension:  torch.Size([103])\n","\n","CovMatrix Dimension  torch.Size([103, 103])\n"]}]},{"cell_type":"markdown","source":["# Predictive Distribution"],"metadata":{"id":"wm_kDQbW6H0G"}},{"cell_type":"code","source":["model.eval() # eval mode is for computing predictions through the model posterior.\n","likelihood.eval()\n","\n","# Make predictions by feeding model through likelihood\n","with torch.no_grad(), gpytorch.settings.fast_pred_var(): # https://arxiv.org/abs/1803.06058\n","    observed_pred = likelihood(model(xTest))# gives us the posterior predictive distribution p(y* | x*, X, y) which is the probability distribution over the predicted output value\n","    mean = observed_pred.mean.numpy()"],"metadata":{"id":"YEUJIZsJ6I1i","executionInfo":{"status":"ok","timestamp":1700582561374,"user_tz":-60,"elapsed":244,"user":{"displayName":"Alexander Sabelström","userId":"16302195271000866589"}}},"execution_count":35,"outputs":[]},{"cell_type":"markdown","source":["# Compute Root Mean Square Error (RMSE)"],"metadata":{"id":"Cdm8bcNYmB-3"}},{"cell_type":"code","source":["yTest = yTest.numpy() # Convert to numpy\n","\n","squared_error = (mean - yTest)**2 # Compute the squared error\n","\n","mean_SE = squared_error.mean() # Compute the mean squared error\n","\n","root_MSE = math.sqrt(mean_SE) # Compute the square root of the mean squared error\n","\n","root_MSE"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"aVxVVxuDmHdw","executionInfo":{"status":"ok","timestamp":1700582564623,"user_tz":-60,"elapsed":3,"user":{"displayName":"Alexander Sabelström","userId":"16302195271000866589"}},"outputId":"5dc32513-42de-483b-ca70-05998e6c548f"},"execution_count":36,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0.3362411856293701"]},"metadata":{},"execution_count":36}]},{"cell_type":"markdown","source":["# Compare different amount of points"],"metadata":{"id":"1r6MvhHyJdRM"}},{"cell_type":"code","source":["# Trains models one by one for each amount of inducing points, and plots each model with plots [rows,columns](must match the length of listOfPoints)\n","def severalInducingPoints(listOfPoints):\n","  maxPoints = len(xTrain) # The max amount of points in training points\n","  for points in listOfPoints:\n","    inducingPointsX = x[:points] # Choose how many points to pick\n","    inducingPointsY = y[:points] # Choose how many points to pick\n","\n","    # initialize likelihood and model\n","    likelihood = gpytorch.likelihoods.GaussianLikelihood() # Decide likelihood\n","    model = GPModel(inducingPointsX, inducingPointsY, likelihood) # Send in inducing points as the training points\n","    if torch.cuda.is_available():\n","        model = model.cuda()\n","        likelihood = likelihood.cuda()\n","    print()\n","    print(\"Inducing Points: \", points)\n","\n","    %timeit train(model, inducingPointsX, inducingPointsY) # Train the model\n","    # Plot\n","    model.eval() # eval mode is for computing predictions through the model posterior.\n","    likelihood.eval()\n","\n","severalInducingPoints([5,10,50,100,200,400, 700, 900, 1030]) # With 1030 being all points\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"dJeE8SmtJibw","executionInfo":{"status":"ok","timestamp":1700424925548,"user_tz":-60,"elapsed":560926,"user":{"displayName":"Alexander Sabelström","userId":"16302195271000866589"}},"outputId":"a5675f54-ad45-4f82-956b-d3597a8da809"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","Inducing Points:  5\n","826 ms ± 139 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n","\n","Inducing Points:  10\n","753 ms ± 9.71 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n","\n","Inducing Points:  50\n","1.3 s ± 649 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n","\n","Inducing Points:  100\n","913 ms ± 12.6 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n","\n","Inducing Points:  200\n","1.6 s ± 337 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n","\n","Inducing Points:  400\n","4.15 s ± 633 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n","\n","Inducing Points:  700\n","13.5 s ± 700 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n","\n","Inducing Points:  900\n","22.5 s ± 987 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n","\n","Inducing Points:  1030\n","25.8 s ± 794 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"]}]},{"cell_type":"code","source":["!"],"metadata":{"id":"PVT15CgXo1tz","executionInfo":{"status":"ok","timestamp":1700582898860,"user_tz":-60,"elapsed":353,"user":{"displayName":"Alexander Sabelström","userId":"16302195271000866589"}},"outputId":"4d0e818b-d076-448b-c448-0d952e4089ba","colab":{"base_uri":"https://localhost:8080/"}},"execution_count":40,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/MyDrive/Project18/GPs\n"]}]}]}